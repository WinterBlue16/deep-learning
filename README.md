# Deep Learning for Natural Language Processing

- Lecture
  - [standford cs224n Natual Language Processing With Deep Learning](http://web.stanford.edu/class/cs224n/)
  - [oxford 2016-2017 Deep Learning for Natural language Process](https://www.cs.ox.ac.uk/teaching/courses/2016-2017/dl/), [lectures](https://github.com/oxford-cs-deepnlp-2017/lectures)
- [understanding-natural-language-deep-neural-networks-using-torch](https://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)
- [deep-learning-nutshell-sequence-learning](https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-sequence-learning/)
- [Deep Learning for NLP(without Magic)](./nlp/socher-lxmls.pdf)
- [Deep Learning for Natural Language Processing](./nlp/2009_tutorial_nips.pdf)
- [Natural Language Processing Application of Deep Learning](./nlp/nlp.pdf)
- [Deep Learning for NLP resources](https://github.com/andrewt3000/DL4NLP/blob/master/README.md)
- [Natural Language Understanding](http://www.inf.ed.ac.uk/teaching/courses/nlu/lectures.html)
- [Natural Language Understanding with Distributed Representations](http://www.kyunghyuncho.me/home/courses/ds-ga-3001-fall-2015)
- [awesome-nlp](https://github.com/keonkim/awesome-nlp#user-content-python)
- [BiLSTM 헤게모니](https://ratsgo.github.io/natural%20language%20processing/2017/10/22/manning/)
- Attention Model
  - [Show, attend and Tell : Neural Image Caption Generation with Visual Attention](https://arxiv.org/pdf/1502.03044v3.pdf)
  - [stackoverflow how to add an attention mechanism in keras](https://stackoverflow.com/questions/42918446/how-to-add-an-attention-mechanism-in-keras)
  - [How to add Attention on top of a Recurrnet Layer Text Classification](https://github.com/keras-team/keras/issues/4962)
  - [Text classification git hub](https://github.com/brightmart/text_classification)
  - [Effective Approaches to Attention-based Neural Machine Translation](https://nlp.stanford.edu/pubs/emnlp15_attn.pdf)
  - Attention is all you need [논문](https://arxiv.org/abs/1706.03762)   [한글 리뷰 ](https://github.com/YBIGTA/DeepNLP-Study/wiki/Attention-Is-All-You-Need-%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0) [Michal Chromiak'sblog ](https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/#.WyZQ1nWFNth)
  - [How to Develop an Encoder-Decoder Model with Attention for Sequence-to-Sequence Prediction in Keras](https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/)
  - [Attention and Memory in Deep Learning and NLP](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/)
  - [keras-attention git hub link](https://github.com/datalogue/keras-attention)
  - [Towards Data Science, Attention Models in NLP a quick introduction](https://towardsdatascience.com/attention-models-in-nlp-a-quick-introduction-2593c1fe35eb)
  - 한글 블로그 
    - [어텐션 메커니즘](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/10/06/attention/) [어텐션 메커니즘2](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/10/06/attention/)
    - [어텐션 메커니즈 시각화](http://docs.likejazz.com/attention/)
    - [딥러닝이 덧셈하는법 어텐션 메커니즘으로 살펴보기](http://freesearch.pe.kr/archives/4724)
    - [what is attention mechanism, youtube 간접 링크](http://hugrypiggykim.com/2018/02/09/%EB%85%BC%EB%AC%B8%EC%9D%BD%EA%B8%B0-effective-approaches-to-attention-based-neural-machine-translation/)
    - [lecture 6 Attention Mechanism](http://dalpo0814.tistory.com/45)
    - [뉴욕대 조경현 교수님 자연어처리 강의](https://www.edwith.org/deepnlp)
- Text Classification
  - [Best Practices for Document Classification with Deep Learning](https://machinelearningmastery.com/best-practices-document-classification-deep-learning/)
    - Word Embedding + CNN
    - Single Layer Cnn Archirecture
    - dial in CNN Hyperparameters
    - Consider Character-Level Cnns
    - Consider Deeper CNNs for Classification
      - [Very Deep Convolution Networks for Text Classification](https://arxiv.org/pdf/1606.01781.pdf)
  - [Document Classification kdnuggets](https://www.kdnuggets.com/2015/01/text-analysis-101-document-classification.html)
  - for Korean
    - [lovit github](https://github.com/lovit/textmining-tutorial)
      - 한국어 텍스트 마이닝을 위한 튜토리얼
    - [Konlpy](https://konlpy-ko.readthedocs.io/)
      - 박은정님이 공개하신 한국어 형태소 분석기 라이브러리 묶음
- Anomaly Detection
  - blog
    - [Neural Networks for Anomaly (Outliers) Detection](https://blog.goodaudience.com/neural-networks-for-anomaly-outliers-detection-a454e3fdaae8) [github link](https://github.com/abelusha/AutoEncoders-for-Anomaly-Detection/blob/master/AutoEncoders-for-Anomaly-Detection.ipynb)
    - [Anomaly Detection in streaming data with LSTMS](https://drive.google.com/file/d/0B_O25s3dlPczREhiNEJOS1prOWs/view)
    - [iot deep learning anomaly detection](https://developer.ibm.com/tutorials/iot-deep-learning-anomaly-detection-5/)
    - [Introduction Anomaly Detection](https://www.kdnuggets.com/2017/04/datascience-introduction-anomaly-detection.html)
    - [credit card fruad detection](https://medium.com/@curiousily/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hackers-part-vii-20e0c85301bd)
  - Githubs 
    - [lstm anomaly detect](https://github.com/aurotripathy/lstm-anomaly-detect)
    - [Anomaly Detection for Temporal Data using LSTM. paper source code](https://github.com/akash13singh/lstm_anomaly_thesis)
    - [RNN-Time-series-Anomaly-Detection](https://github.com/chickenbestlover/RNN-Time-series-Anomaly-Detection)
      - HOT SAX: Efficiently Finding the Most Unusual Time Series Subsequence." In The Fifth IEEE International Conference on Data Mining. (2005) 
    - [LSTM Based Anomaly Detection](https://github.com/jramapuram/LSTM_Anomaly_Detector)
    - [Keras Anomaly Detection](https://github.com/chen0040/keras-anomaly-detection)
    - [Anomaly Detection in Streaming Data with LSTMs](https://github.com/marionleborgne/lstm-talk)
    - [AutoEncoders-for-Anomaly-Detection](https://github.com/abelusha/AutoEncoders-for-Anomaly-Detection)
    - 

# chatbot
- [DEEP LEARNING FOR CHATBOTS, PART 1 – INTRODUCTION](http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/)
- [ChatterBot](https://github.com/gunthercox/ChatterBot)
- [From Language to Information](./chatbot/chatbot.pdf)

# Distribute Computing
- [Hadoop 설정](./distribute/hadoop_config.md)
- [Spark 설정](./distribute/spark_config.md)

# [Reinforce Learning](./rl.md) 


# Deep Learning Library
- 범용 라이브러리 
  [Keras](./keras/README.md)
  [Theano](./Theano/README.MD)
  [tensorflow](./tensorflow/README.MD)
- TF eager mode (./tensorflow-eager)
- 이미지 특화 라이브러리 
  [openface](./openface/README.md)

# DeepLearning Sites 
- [http://www.wildml.com/](http://www.wildml.com/)
- [Machine Learning Cookbook](https://www.gitbook.com/book/bigaidream/subsets_ml_cookbook/details)
- [앤드류 응 교수 인터뷰...](http://events.technologyreview.com/emtech/digital/16/video/watch/andrew-ng-deep-learning/)
- [스탠포드대 기계학습 코세라 강의](https://www.coursera.org/learn/machine-learning/home/welcome)

# CNN 관련 컨텐츠
- [컨불루션 뉴럴넷1](http://t-robotics.blogspot.kr/2016/05/convolutional-neural-network_31.html#.V1ZrWpOLSlM)
- [컨불루션 뉴럴넷2](http://keunwoochoi.blogspot.kr/2015/07/convolutional-neural-network.html)
- [컨불루션 뉴럴넷 개요](http://keunwoochoi.blogspot.kr/search/label/CNNs)

# 얼굴인식
- [얼굴인식](./faceRecon/contents.md)

# 강화학습
- [퐁을 학습 시키자](http://keunwoochoi.blogspot.kr/2016/06/andrej-karpathy.html)

# 블로그 
- [CNN으로 인물 인식 시키기 삽질기.](./blog/post1/contents.md)
- [openface로 얼굴 인식 시키기](./blog/post3/content.md)

# SPARK
- [BerkeleyX: CS105x Introduction to Apache Spark 정리](./SPARK/Introduction to Apache Spark_정리.md)
